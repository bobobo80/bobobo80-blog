Title: Scrapy和pyspider框架浅谈
Date: 2018-09-01
Category: Tech
Tags: python

自己现在也算是小小抓取工程师了，在公司也在撸自己的框架，在这之前也有使用和了解过python语言实现的最著名的两个框架，先来简单说一说。

### scrapy

scrapy框架应该算是最著名的框架了，不用它也应该对其有所了解吧。scrapy基于twisted异步框架编写，理论上爬取的过程中都是在同一个线程中的，利用异步的机制实现下载和后处理不堵塞，所以在解析和存储过程中，如果数据库操作时间长，需要使用twisted的数据库连接进行操作。在中间件等中使用time.sleep这种操作肯定也是会堵塞所有的操作的。

在我看来scrapy最好的设计是中间件设计（[和django插件思路很像](https://docs.scrapy.org/en/latest/faq.html#did-scrapy-steal-x-from-django)），在下载、解析、存储中提供了可组合的模块化配置，为各种复用提供了帮助。

scrapy的结构组成非常的经典了，分成引擎，调度器，下载器，解析器spider，item pipeline结果处理几个部分，虽然基本所有框架都是这么划分的，但是和pyspider比还是有所不同的。scrapy是一个进程集成所有内容，如果是需要分布式，依靠调度器的队列来分布式处理。这种情况就是分布式的每个节点上都包含引擎，下载，解析等。当然可以使用另外的策略，让scrapy只下载，通过其他方式来处理其他的部分。

### pyspider

那么其实从结构上来说，pyspider从这个层面和scrapy是完全的不同的。pyspider将调度，下载，解析按进程分开，使用消息队列进行连接，所以说pyspider的各个功能是相对独立的，分布式情况下，各个功能进程可以拆分开部署等，所以结构上分开的。

另一个明显的区别是pyspider对不同任务的管理，相对于scrapy能够在更高一个层级的进行管理，pyspider中的webui管理相当于对多个项目进行管理，这一点在scrapy是没有这个层级的东西的，scrapyd配合相关的webui管理项目（比如gerapy）才是这个层级的一个实现。

在项目开发上，pyspider一般是单文件上进行开发，还没有原生中间件机制，如果需要利用模块化的方式重用一些功能，好像无法完全通过webui的那个管理系统实现，需要在终端部署依赖的各种重用功能的文件。所以其实比较偏向于大量简单爬虫项目的集中管理。而scrapy本身可以更方便的扩展，更容易完成复杂的需求。

源码上来说，pyspider还很单薄，不过好处是也比较容易读，而scrapy再配合上其依赖的twisted，嗯，够喝一壶的了。

### 小结

所以两个框架还是有很大不同的，从结构上说我更倾向于pyspider，因为各个爬虫的核心功能能够更大的解耦。不过仅就pyspider，可能还是相对偏向简单任务，对于功能的复用等方面，还比较好的支持。